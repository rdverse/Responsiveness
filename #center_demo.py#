import os
import pathlib
import cv2
import time
import argparse
import math

import matplotlib
import matplotlib.pyplot as plt

import io
import scipy.misc
import numpy as np
from six import BytesIO
from PIL import Image, ImageDraw, ImageFont
from six.moves.urllib.request import urlopen

import tensorflow as tf
import tensorflow_hub as hub

tf.get_logger().setLevel('ERROR')

from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.utils import ops as utils_ops

from center_utils import *
# from detection import DetectionSetupMode, compareData, Person

PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'
category_index = label_map_util.create_category_index_from_labelmap(
    PATH_TO_LABELS, use_display_name=True)

ROOT_DIR = os.getcwd()
# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "mylogs")
# Local path to trained weights file

COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco_humanpose.h5")

#import tensorflow as tf
#physical_devices = tf.config.enxperimental.list_phyiscal_device('GPU')
#tf.config.experimental.set_memory_growth(physical_devices[0], True)
os.environ['TFHUB_CACHE_DIR'] = 'cache'

# load tensorflow hub model
model_handle = 'CenterNet HourGlass104 Keypoints 512x512'
model_handle = 'CenterNet HourGlass104 Keypoints 1024x1024'

print('loading model...')
hub_model = hub.load(ALL_MODELS[model_handle])
print('model loaded!')
'''
Function for adding arguments through argparse
'''


def str2bool(v):
    if isinstance(v, bool):
        return v
    if v[0].lower() == 't':
        return True
    elif v[1].lower() == 'f':
        return False


def get_argparser():
    parser = argparse.ArgumentParser(
        description='CenterNet for keypoints detection', add_help=True)
    parser.add_argument(
        "--initialize",
        default=False,
        type=str2bool,
        help='Populate all files to group directory ? (True or False)')

    parser.add_argument(
        "--video_input",
        help='Just add the name of the video file in box_data dir')

    parser.add_argument("--video_output",
                        default=True,
                        type=str2bool,
                        help="Do you want video output ? (True or False)")
    return parser


def get_detections(image_np):
    # running inference
    results = hub_model(image_np)

    # different object detection models have additional results
    # all of them are explained in the documentation
    result = {key: value.numpy() for key, value in results.items()}
    print(result.keys())

    label_id_offset = 0
    image_np_with_detections = image_np.copy()

    # Use keypoints if available in detections
    keypoints, keypoint_scores = None, None
    if 'detection_keypoints' in result:
        keypoints = result['detection_keypoints'][0]
        keypoint_scores = result['detection_keypoint_scores'][0]

    viz_utils.visualize_boxes_and_labels_on_image_array(
        image_np_with_detections[0],
        result['detection_boxes'][0],
        (result['detection_classes'][0] + label_id_offset).astype(int),
        result['detection_scores'][0],
        category_index,
        use_normalized_coordinates=True,
        max_boxes_to_draw=200,
        min_score_thresh=.30,
        agnostic_mode=False,
        keypoints=keypoints,
        keypoint_scores=keypoint_scores,
        keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)

    return (image_np_with_detections, result)


args = get_argparser().parse_args()

if args.initialize:
    multiplier = 5
else:
    multiplier = 0.5

groupPATH = 'groupPATH'
#Directory setup
if not os.path.isdir(groupPATH):
    os.mkdir(groupPATH)

# Other static declarations
cnt = 0
vidFile = os.path.join('box_data', args.video_input)

cap = cv2.VideoCapture(vidFile)
size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
codec = cv2.VideoWriter_fourcc(*'DIVX')
fps = int(cap.get(cv2.CAP_PROP_FPS))
frame_rate_divider = int(fps * multiplier)
output = cv2.VideoWriter('huma.avi', codec, int(1 / multiplier), size)

# read the video

while (cap.isOpened()):
    stime = time.time()

    try:
        ret, frame = cap.read()
        image_np = np.array([frame])

    except:
        continue

    if ret:
        if cnt % frame_rate_divider == 0:
            frame_keypoints, results = get_detections(image_np)
            # for one image
            imgList = list()
            #Go through the masked images and save them in a folder
            results = {key: val[0] for key, val in results.items()}
            for no in range(int(results["num_detections"])):
                if results["detection_scores"][no] > 0.30:
                    box = results["detection_boxes"][no]
                    image_name = os.path.join(
                        groupPATH,
                        str(no) + '_' + str(cnt) + '.jpg')

                    Y1, X1, Y2, X2 = tuple(box)
                    frame_copy = image_np.copy()
                    frame_copy = frame_copy[math.floor(Y1):math.ceil(Y2),
                                            math.floor(X1):math.ceil(X2)]

                    imgList.append(frame_copy)
                    if args.initialize:
                        cv2.imwrite(image_name, frame_copy)

            results['images'] = imgList

                if not args.initialize:
                     if cnt == 0:
                         #This sets up the csv and directories in the mainPath
                         detector = DetectionSetupMode()
                     else:
                #         detector.classifyDetections(results, cnt)

            if args.video_output:
                output.write(np.squeeze(frame_keypoints))

            print(cnt)
            print('Time elapsed in the video : {} minutes'.format(
                (cnt / (fps * 60))))
            cnt += 1
        else:
            cnt += 1
    else:
        break
        print("stuck here?")

cap.release()
output.release()
